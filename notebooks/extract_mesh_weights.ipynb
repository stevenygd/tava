{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n",
      "/home/guandao/tava/env/tava/bin/python\n",
      "env: CUDA_VISIBLE_DEVICES=6\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "!which python\n",
    "%env CUDA_VISIBLE_DEVICES=6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import os\n",
    "from hydra import initialize, compose\n",
    "from hydra.utils import instantiate\n",
    "from omegaconf import OmegaConf\n",
    "from tava.utils.training import resume_from_ckpt\n",
    "from tava.models.basic.mipnerf import cylinder_to_gaussian\n",
    "\n",
    "device = \"cuda\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # args for data\n",
    "# ARGS_ANIMAL_WOLF = [\n",
    "#     \"dataset=animal_wolf\", \"dataset.root_fp=/home/ruilongli/data/forest_and_friends_rendering/\",\n",
    "#     \"hydra.run.dir=/home/ruilongli/workspace/TAVA/outputs/release/animal_wolf/Wolf_cub_full_RM_2/snarf/\",\n",
    "# ]\n",
    "# ARGS_ANIMAL_HARE=[\n",
    "#     \"dataset=animal_hare\", \"dataset.root_fp=/home/ruilongli/data/forest_and_friends_rendering/\",\n",
    "#     \"hydra.run.dir=/home/ruilongli/workspace/TAVA/outputs/release/animal_hare/Hare_male_full_RM/snarf/\",\n",
    "# ]\n",
    "# ARGS_ZJU_313=[\n",
    "#     \"dataset=zju\", \"dataset.subject_id=313\", \"dataset.root_fp=/home/ruilongli/data/zju_mocap/neuralbody/\",\n",
    "#     \"hydra.run.dir=/home/ruilongli/workspace/TAVA/outputs/release/zju_mocap/313/snarf/\",\n",
    "# ]\n",
    "# ARGS_ZJU_315=[\n",
    "#     \"dataset=zju\", \"dataset.subject_id=315\", \"dataset.root_fp=/home/ruilongli/data/zju_mocap/neuralbody/\",\n",
    "#     \"hydra.run.dir=/home/ruilongli/workspace/TAVA/outputs/release/zju_mocap/315/snarf/\",\n",
    "# ]\n",
    "# \n",
    "# # args for method\n",
    "# ARGS_TAVA_ANIMAL=[\"pos_enc=snarf\", \"loss_bone_w_mult=1.0\", \"pos_enc.offset_net_enabled=false\", \"model.shading_mode=null\"]\n",
    "# ARGS_TAVA_ZJU=[\"pos_enc=snarf\", \"loss_bone_w_mult=1.0\", \"pos_enc.offset_net_enabled=true\", \"model.shading_mode=implicit_AO\"]\n",
    "\n",
    "# ARGS for method\n",
    "project_dir = \"/home/guandao/tava\"\n",
    "subject_id = 2\n",
    "ARGS_TAVA_HUMANRF = [\n",
    "    \"dataset=humanrf\", \n",
    "    f\"dataset.subject_id={subject_id:02d}\",\n",
    "    \"dataset.post_fix='_qual'\",\n",
    "    \"pos_enc=snarf\",\n",
    "    \"loss_bone_w_mult=1.0\",\n",
    "    \"loss_bone_offset_mult=0.1\",\n",
    "    \"engine=evaluator\",\n",
    "    \"pos_enc.offset_net_enabled=true\", \n",
    "    \"model.shading_mode=implicit_AO\",\n",
    "    f\"hydra.run.dir=/home/guandao/tava/pretrained/actor{subject_id:02d}\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# here we set the arguments for ZJU_313 as an example.\n",
    "# overrides = [\"resume=True\"] + ARGS_ANIMAL_HARE + ARGS_TAVA_ANIMAL\n",
    "overrides = [\"resume=True\"] + ARGS_TAVA_HUMANRF \n",
    "\n",
    "# create the cfg\n",
    "with initialize(config_path=\"../configs\"):\n",
    "    cfg = compose(config_name=\"mipnerf_dyn_humanrf\", overrides=overrides, return_hydra_config=True)\n",
    "    OmegaConf.resolve(cfg.hydra)\n",
    "    save_dir = cfg.hydra.run.dir\n",
    "    ckpt_dir = os.path.join(save_dir, \"checkpoints\")\n",
    "    \n",
    "# initialize model and load ckpt\n",
    "model = instantiate(cfg.model).to(device)\n",
    "_ = resume_from_ckpt(\n",
    "    path=ckpt_dir, model=model, step=cfg.resume_step, strict=True,\n",
    ")\n",
    "assert os.path.exists(ckpt_dir), \"ckpt does not exist! Please check.\"\n",
    "\n",
    "# initialize dataset\n",
    "dataset = instantiate(\n",
    "    cfg.dataset, split=\"train\", num_rays=None, cache_n_repeat=None,\n",
    ")\n",
    "meta_data = dataset.build_pose_meta_info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a color pattern for visualization\n",
    "torch.manual_seed(412)\n",
    "colorbases = torch.rand((cfg.dataset.n_transforms + 1, 3)) * 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# As the Mip-NeRF requires a covariance for density & color querying,\n",
    "# we here *estimate* a `cov` based on the size of the subject and the \n",
    "# number of sampled points. It can be estimated in other ways such as\n",
    "# average of cov during training.\n",
    "\n",
    "radii = dataset[0][\"rays\"].radii.mean().to(device)\n",
    "rest_verts = torch.from_numpy(\n",
    "    dataset.parser.load_meta_data()[\"rest_verts\"]\n",
    ").to(device)\n",
    "bboxs_min = rest_verts.min(dim=0).values\n",
    "bboxs_max = rest_verts.max(dim=0).values\n",
    "subject_size = torch.prod(bboxs_max - bboxs_min) ** (1./3.)\n",
    "t0, t1 = 0, subject_size / model.num_samples\n",
    "d = torch.tensor([0., 0., 1.]).to(device)\n",
    "_, cov = cylinder_to_gaussian(d, t0, t1, radii, model.diag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a grid coordinates to be queried in canonical.\n",
    "\n",
    "def create_grid3D(min, max, steps, device=\"cpu\"):\n",
    "    if type(min) is int:\n",
    "        min = (min, min, min) # (x, y, z)\n",
    "    if type(max) is int:\n",
    "        max = (max, max, max) # (x, y)\n",
    "    if type(steps) is int:\n",
    "        steps = (steps, steps, steps) # (x, y, z)\n",
    "    arrangeX = torch.linspace(min[0], max[0], steps[0]).to(device)\n",
    "    arrangeY = torch.linspace(min[1], max[1], steps[1]).to(device)\n",
    "    arrangeZ = torch.linspace(min[2], max[2], steps[2]).to(device)\n",
    "    gridX, girdY, gridZ = torch.meshgrid([arrangeX, arrangeY, arrangeZ], indexing=\"ij\")\n",
    "    coords = torch.stack([gridX, girdY, gridZ]) # [3, steps[0], steps[1], steps[2]]\n",
    "    coords = coords.view(3, -1).t() # [N, 3]\n",
    "    return coords\n",
    "_center = (bboxs_max + bboxs_min) / 2.0\n",
    "_scale = (bboxs_max - bboxs_min) / 2.0\n",
    "bboxs_min_large = _center - _scale * 1.5\n",
    "bboxs_max_large = _center + _scale * 1.5\n",
    "res = 512\n",
    "coords = create_grid3D(bboxs_min_large, bboxs_max_large, res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6554/6554 [00:18<00:00, 349.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.) tensor(821.5773) tensor(0.3133)\n"
     ]
    }
   ],
   "source": [
    "# Query the density grid in the canonical\n",
    "\n",
    "from tqdm import tqdm\n",
    "from tava.utils.bone import closest_distance_to_points\n",
    "from tava.utils.structures import namedtuple_map\n",
    "\n",
    "bones_rest = namedtuple_map(lambda x: x.to(device), meta_data[\"bones_rest\"])\n",
    "chunk_size = 20480\n",
    "densities = []\n",
    "with torch.no_grad():\n",
    "    for i in tqdm(range(0, coords.shape[0], chunk_size)):\n",
    "        coords_chunk = coords[i: i + chunk_size].to(device)\n",
    "        \n",
    "        dists = closest_distance_to_points(bones_rest, coords_chunk).min(dim=-1).values\n",
    "        selector = dists <= cfg.dataset.cano_dist\n",
    "\n",
    "        posi_enc = model.pos_enc.posi_enc((coords_chunk, cov.expand_as(coords_chunk)))\n",
    "        sigma = model.mlp.query_sigma(posi_enc, masks=selector, return_feat=False)\n",
    "        density = model.density_activation(sigma + model.density_bias)\n",
    "        densities.append(density.cpu())\n",
    "densities = torch.cat(densities, dim=0).reshape(res, res, res)\n",
    "print (densities.min(), densities.max(), densities.median())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([468093, 3])\n"
     ]
    }
   ],
   "source": [
    "# Marching cube to get the mesh. We use the threshold 5.0 for all cases. You might want\n",
    "# to adjust that with your own data. Note installing torchmcubes would take some time.\n",
    "\n",
    "# excute this in juputer to install: \"!pip install git+https://github.com/tatsy/torchmcubes.git\"\n",
    "from torchmcubes import marching_cubes\n",
    "\n",
    "verts, faces = marching_cubes(densities, 5.0)\n",
    "verts = verts[..., [2, 1, 0]] / res * (bboxs_max_large - bboxs_min_large).cpu() + bboxs_min_large.cpu()\n",
    "print (verts.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export Mesh with Skinning Weights\n",
    "\n",
    "def save_obj_mesh(mesh_path, verts, faces):\n",
    "    file = open(mesh_path, 'w')\n",
    "    for v in verts:\n",
    "        file.write('v %.4f %.4f %.4f\\n' % (v[0], v[1], v[2]))\n",
    "    for f in faces:\n",
    "        f_plus = f + 1\n",
    "        file.write('f %d %d %d\\n' % (f_plus[0], f_plus[1], f_plus[2]))\n",
    "    file.close()\n",
    "\n",
    "def save_obj_mesh_with_color(mesh_path, verts, faces, colors):\n",
    "    file = open(mesh_path, 'w')\n",
    "\n",
    "    for idx, v in enumerate(verts):\n",
    "        c = colors[idx]\n",
    "        file.write('v %.4f %.4f %.4f %.4f %.4f %.4f\\n' % (v[0], v[1], v[2], c[0], c[1], c[2]))\n",
    "    for f in faces:\n",
    "        f_plus = f + 1\n",
    "        file.write('f %d %d %d\\n' % (f_plus[0], f_plus[1], f_plus[2]))\n",
    "    file.close()\n",
    "\n",
    "chunk_size = 8192\n",
    "weights = []\n",
    "with torch.no_grad():\n",
    "    for i in range(0, verts.shape[0], chunk_size):\n",
    "        verts_chunk = verts[i: i + chunk_size].to(device)\n",
    "        weights_chunk = model.pos_enc.query_weights(verts_chunk)\n",
    "        weights.append(weights_chunk.cpu())\n",
    "weights = torch.cat(weights, dim=0)\n",
    "\n",
    "save_dir = f\"/home/guandao/tava/pretrained/actor{subject_id:02d}\"\n",
    "colors = (weights[..., None] * colorbases).sum(dim=-2)\n",
    "save_obj_mesh_with_color(\n",
    "    os.path.join(save_dir, \"extracted_cano_mesh_soft_weight.obj\"), \n",
    "    verts.cpu().numpy(), faces.cpu().numpy(), colors.cpu().numpy() / 255.0\n",
    ")\n",
    "\n",
    "colors = colorbases[weights.argmax(dim=-1)]\n",
    "save_obj_mesh_with_color(\n",
    "    os.path.join(save_dir, \"extracted_cano_mesh_hard_weight.obj\"), \n",
    "    verts.cpu().numpy(), faces.cpu().numpy(), colors.cpu().numpy() / 255.0\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6b6dbf4df62a4df58a1b76168620a2bb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Renderer(camera=PerspectiveCamera(children=(DirectionalLight(color='white', intensity=0.6, position=(0.1252925…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<meshplot.Viewer.Viewer at 0x7f87300f5a30>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import meshplot as mp\n",
    "mp.plot(verts.cpu().numpy(), faces.cpu().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/guandao/tava/pretrained/actor02'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "save_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "f156ac58ad89dad164aee97f58386e335ecc1447b9ed93fd42b558e9d07d43f1"
  },
  "kernelspec": {
   "display_name": "Python 3.7.11 ('tava')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
